{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.9.2 requires numpy<1.26.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformer_lens -q\n",
    "!pip install --upgrade attrs -q\n",
    "!pip uninstall jax jaxlib -y -q\n",
    "!pip install jax jaxlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "from src.neuron_texts import find_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# model_name = \"pythia-410m\"\n",
    "model_name = \"gpt2-large\"\n",
    "device = \"cuda\"\n",
    "# layers = [9, 10, 11]\n",
    "# layers = [20, 21, 22, 23]\n",
    "layers = [31, 32, 33, 34, 35]\n",
    "num_neurons_per_layer = 20\n",
    "rejected_neurons = [()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af530ada1ec146c59641bfc44c32bebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc503beeb66f456db7ab6e11f1166fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bbe53109eb4a228b5eecbbde838c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57853cf4df84079a554fd09977c2c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1f7665e9954e5fb2c81e39fb13b7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce9c3bae5244597abe70319717bfce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-large into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from fancy_einsum import einsum\n",
    "import torch\n",
    "\n",
    "def find_random_neurons(model, layers, num_neurons_per_layer, rejected_neurons):\n",
    "    results = {}\n",
    "    rejected_neurons_with_tokens = []\n",
    "\n",
    "    # Handle layers if they are negative\n",
    "    num_layers = model.cfg.n_layers\n",
    "    layers = [layer if layer >= 0 else num_layers + layer for layer in layers]\n",
    "\n",
    "    for layer_num in layers:\n",
    "        n_layer_neurons = model.W_out[layer_num, :, :]\n",
    "        unembedding = model.W_U\n",
    "        dot_product = einsum(\"neuron embed, embed token -> neuron token\", n_layer_neurons, unembedding)\n",
    "        \n",
    "        values, indices = torch.max(dot_product, dim=-1) # Get the highest congruence with any given token for each neuron\n",
    "        top_values, top_indices = torch.topk(values, indices.shape[0])\n",
    "\n",
    "\n",
    "        found_i = []\n",
    "        while len(found_i) < num_neurons_per_layer:\n",
    "            i = random.randint(0, len(top_indices))\n",
    "            if i in found_i:\n",
    "                continue\n",
    "            else:\n",
    "                str_token = model.to_string(indices[top_indices][i])\n",
    "                found_i.append(i)\n",
    "                neuron_index = top_indices[i].item()\n",
    "                results[(layer_num, neuron_index)] = {'token': str_token, 'congruence': top_values[i].item()}\n",
    "\n",
    "    return results, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3772) ' that'\n",
      "(20, 1625) ' of'\n",
      "(20, 2216) ' and'\n",
      "(20, 3388) ' at'\n",
      "(20, 2152) ' that'\n",
      "(20, 1477) ' right'\n",
      "(20, 2446) ' over'\n",
      "(20, 718) ' of'\n",
      "(20, 1234) ' one'\n",
      "(20, 1365) ' would'\n",
      "(20, 2937) ' or'\n",
      "(20, 1198) ' so'\n",
      "(20, 2897) ' even'\n",
      "(20, 3622) ' to'\n",
      "(20, 2451) ' of'\n",
      "(20, 1334) ' so'\n",
      "(20, 144) ' the'\n",
      "(20, 3711) ' to'\n",
      "(20, 2950) ' had'\n",
      "(20, 3809) ' was'\n",
      "(21, 1863) ' about'\n",
      "(21, 2711) ' or'\n",
      "(21, 110) ' can'\n",
      "(21, 3412) ' have'\n",
      "(21, 3120) ' in'\n",
      "(21, 1215) ' too'\n",
      "(21, 1832) ' of'\n",
      "(21, 758) ' Its'\n",
      "(21, 2501) ' for'\n",
      "(21, 4076) ' at'\n",
      "(21, 3267) ' on'\n",
      "(21, 354) ' for'\n",
      "(21, 3247) ' time'\n",
      "(21, 825) ' its'\n",
      "(21, 808) ' in'\n",
      "(21, 169) ' work'\n",
      "(21, 3537) ' issue'\n",
      "(21, 1725) ' would'\n",
      "(21, 4050) ' that'\n",
      "(21, 1017) ' no'\n",
      "(22, 2896) ' one'\n",
      "(22, 1074) ' not'\n",
      "(22, 974) ' do'\n",
      "(22, 3561) ' on'\n",
      "(22, 855) ' the'\n",
      "(22, 1166) ' current'\n",
      "(22, 3822) ' and'\n",
      "(22, 1268) ' by'\n",
      "(22, 911) ' at'\n",
      "(22, 1918) ' and'\n",
      "(22, 1661) ' on'\n",
      "(22, 2005) ' in'\n",
      "(22, 3667) ' all'\n",
      "(22, 2146) ' based'\n",
      "(22, 1762) ' state'\n",
      "(22, 961) ' that'\n",
      "(22, 1403) ' the'\n",
      "(22, 3319) ' the'\n",
      "(22, 307) ' he'\n",
      "(22, 1582) ' in'\n",
      "(23, 682) ' as'\n",
      "(23, 872) ' but'\n",
      "(23, 2000) ' her'\n",
      "(23, 1578) ' as'\n",
      "(23, 2259) ' at'\n",
      "(23, 1172) ' over'\n",
      "(23, 969) ' at'\n",
      "(23, 2059) ' won'\n",
      "(23, 2483) ' on'\n",
      "(23, 3308) ' should'\n",
      "(23, 3188) ' an'\n",
      "(23, 2874) ' as'\n",
      "(23, 805) ' was'\n",
      "(23, 3814) ' in'\n",
      "(23, 178) ' herself'\n",
      "(23, 797) ' produced'\n",
      "(23, 3843) ' to'\n",
      "(23, 176) ' at'\n",
      "(23, 1809) ' could'\n",
      "(23, 1159) ' needed'\n"
     ]
    }
   ],
   "source": [
    "# rejected_neurons = [(9, 2322), (9, 2894), (11, 3033)] # GPT-2 Small, 20 neurons per layer\n",
    "# rejected_neurons = [(23, 3671), (23, 3177)] # GPT-2 Medium, 20 neurons per layer\n",
    "# rejected_neurons = [(31, 4172), (31, 4899), (32, 4361), (33, 1582), (33, 122), (33, 2587), \n",
    "#                     (34, 2978), (34, 805), (35, 274), (35, 920), (35, 4849), (35, 684), \n",
    "#                     (35, 4396), (35, 295), (35, 3065), (35, 989)]  # GPT-2 Large, 40 neurons per layer\n",
    "# rejected_neurons = [(44, 1657), (45, 284),(45, 4415) ,(46, 1785),(46, 1795),(47, 2065),\n",
    "                    # (47, 1147),(47, 3489), (47, 4845),(47, 5429),(47, 4019),\n",
    "                    # (43, 403),(47, 6356),(47, 3775),(47, 3635),] # GPT-2 XL, 20 neurons per layer\n",
    "\n",
    "# rejected_neurons = [(16, 2727), (16, 523), (17, 4787),(18, 2078),(18, 123),(18, 4681),(19, 5095),(19, 4034),(20, 2259),(16, 4244),(20,795)] # GPT-2-large mid\n",
    "\n",
    "# rejected_neurons = [(9, 2871), (10, 741), (10, 336), (11, 1266) , (11, 493) ,(11, 817) ,(11, 922),(11, 2790),(11, 1953) ,(11, 2209) ,(11, 2631) ,(11, 2640) ,(11, 803) ,(11, 875) ,(11, 2856),(11, 1240) ,(11, 339),(11, 1248),(11, 1994),\n",
    "                    # (11, 1828),(11, 1076),(11, 1347), (11,110), (11,45), (11, 334), (11,1932)] # pythia 160m\n",
    "# rejected_neurons = [(10, 457), (11,2627)]\n",
    "\n",
    "\n",
    "# Update this until you are satisfied with the results\n",
    "\n",
    "neuron_results, rejected_neurons_with_token = find_neurons(\n",
    "    model=model,\n",
    "    layers=layers,\n",
    "    num_neurons_per_layer=num_neurons_per_layer,\n",
    "    rejected_neurons=rejected_neurons,\n",
    ")\n",
    "\n",
    "for k, v in neuron_results.items():\n",
    "    print(k, f\"'{v['token']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 396) ' Diver'\n",
      "(31, 2420) ' Dragonbound'\n",
      "(31, 160) ' arms'\n",
      "(31, 2798) 'affe'\n",
      "(31, 4364) '�'\n",
      "(31, 302) 'safety'\n",
      "(31, 3564) ' like'\n",
      "(31, 1788) 'hus'\n",
      "(31, 2959) ' Badge'\n",
      "(31, 1055) 'ğ'\n",
      "(31, 4457) ' Burk'\n",
      "(31, 1790) 'etta'\n",
      "(31, 2443) ' in'\n",
      "(31, 4543) 'ructure'\n",
      "(31, 4173) 'cel'\n",
      "(31, 2459) ' Central'\n",
      "(31, 751) 'ounces'\n",
      "(31, 3811) 'eworthy'\n",
      "(31, 365) 'ilst'\n",
      "(31, 3352) ' guiActiveUnfocused'\n",
      "(32, 2304) ' glimps'\n",
      "(32, 1710) ' Dy'\n",
      "(32, 2100) 'agy'\n",
      "(32, 4063) 'ANS'\n",
      "(32, 4569) ' also'\n",
      "(32, 1993) ' Material'\n",
      "(32, 3349) ' case'\n",
      "(32, 4722) ' coverage'\n",
      "(32, 3629) ' the'\n",
      "(32, 2999) ' ©'\n",
      "(32, 2285) 'sn'\n",
      "(32, 3430) 'IME'\n",
      "(32, 63) ' and'\n",
      "(32, 4325) ' ba'\n",
      "(32, 3669) ' Definition'\n",
      "(32, 4563) 'iably'\n",
      "(32, 2954) 'umo'\n",
      "(32, 365) 'ern'\n",
      "(32, 1449) ' right'\n",
      "(32, 4973) ' free'\n",
      "(33, 2844) ' ending'\n",
      "(33, 3552) 'anski'\n",
      "(33, 3193) ' waiver'\n",
      "(33, 4388) 'esville'\n",
      "(33, 2896) ' phot'\n",
      "(33, 539) ' Kis'\n",
      "(33, 386) ' sober'\n",
      "(33, 2766) ' Gilbert'\n",
      "(33, 4757) ' clad'\n",
      "(33, 4695) 'track'\n",
      "(33, 1546) 'acci'\n",
      "(33, 2260) 'APD'\n",
      "(33, 4322) 'hold'\n",
      "(33, 900) ' 0'\n",
      "(33, 3395) ' HOME'\n",
      "(33, 2701) ' said'\n",
      "(33, 2432) 'iors'\n",
      "(33, 1473) ' Reviews'\n",
      "(33, 1984) 'shows'\n",
      "(33, 328) 'manship'\n",
      "(34, 1002) 'abouts'\n",
      "(34, 362) 'WIND'\n",
      "(34, 643) 'urus'\n",
      "(34, 2560) 'UI'\n",
      "(34, 4453) 'amiya'\n",
      "(34, 1234) ' Various'\n",
      "(34, 1378) ' Influence'\n",
      "(34, 3840) 'database'\n",
      "(34, 2068) ' Area'\n",
      "(34, 3557) ' critical'\n",
      "(34, 4333) 'ique'\n",
      "(34, 2882) ' fuzz'\n",
      "(34, 3281) 'Dash'\n",
      "(34, 3898) ' case'\n",
      "(34, 4099) 'them'\n",
      "(34, 3696) 'scribe'\n",
      "(34, 847) 'annot'\n",
      "(34, 1994) ' using'\n",
      "(34, 1222) ' Gap'\n",
      "(34, 1434) 'uci'\n",
      "(35, 864) '\t'\n",
      "(35, 3533) 'repl'\n",
      "(35, 4541) 'render'\n",
      "(35, 799) 'iciary'\n",
      "(35, 30) ' He'\n",
      "(35, 4374) ' horizont'\n",
      "(35, 1011) ' \"'\n",
      "(35, 1735) 'tail'\n",
      "(35, 4452) 'acl'\n",
      "(35, 3109) '�'\n",
      "(35, 2206) '\u001d'\n",
      "(35, 4708) ' Chance'\n",
      "(35, 1970) 'dust'\n",
      "(35, 1914) ' uncond'\n",
      "(35, 4791) 'ix'\n",
      "(35, 552) 'otin'\n",
      "(35, 1120) ' TheNitrome'\n",
      "(35, 1600) ' Sparkle'\n",
      "(35, 2496) 'atory'\n",
      "(35, 2939) 'el'\n"
     ]
    }
   ],
   "source": [
    "random_neuron_results, _ = find_random_neurons(\n",
    "    model=model,\n",
    "    layers=layers,\n",
    "    num_neurons_per_layer=num_neurons_per_layer,\n",
    "    rejected_neurons=rejected_neurons,\n",
    ")\n",
    "\n",
    "for k, v in random_neuron_results.items():\n",
    "    print(k, f\"'{v['token']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output of this notebook\n",
    "output = {\n",
    "    'parameters': {\n",
    "        'model_name': model_name,\n",
    "        'layers': layers,\n",
    "        'num_neurons_per_layer': num_neurons_per_layer,\n",
    "        'rejected_neurons': rejected_neurons_with_token,\n",
    "    },\n",
    "    'neurons': {str(k): v for k,v in neuron_results.items()},\n",
    "}\n",
    "\n",
    "# Save the output to a in ../data/neurons/\n",
    "timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(int(time.time())))\n",
    "filename = f\"{timestamp}_{model_name}.json\"\n",
    "\n",
    "with open(f\"./experiment_data/1_next_token_neurons/{filename}\", 'w') as f:\n",
    "    json.dump(output, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output of this notebook, for random neuron\n",
    "output = {\n",
    "    'parameters': {\n",
    "        'model_name': model_name,\n",
    "        'layers': layers,\n",
    "        'num_neurons_per_layer': num_neurons_per_layer,\n",
    "        # 'rejected_neurons': rejected_neurons_with_token,\n",
    "        'rejected_neurons': [],\n",
    "    },\n",
    "    'neurons': {str(k): v for k,v in random_neuron_results.items()},\n",
    "}\n",
    "\n",
    "# Save the output to a in ../data/neurons/\n",
    "timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(int(time.time())))\n",
    "filename = f\"{timestamp}_{model_name}_random.json\"\n",
    "\n",
    "with open(f\"./experiment_data/1_next_token_neurons/{filename}\", 'w') as f:\n",
    "    json.dump(output, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
