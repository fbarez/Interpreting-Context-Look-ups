{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "from src.neuron_heads import head_attribution_over_all_data\n",
    "from src.datahandlers import ActivatingDataset\n",
    "from src.utils import tuple_str_to_tuple\n",
    "from src.neuron_explain import generate_classify_prompt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"2023-10-13_13-51-37_gpt2-small_test\"\n",
    "# filename = \"2023-10-13_14-02-06_gpt2-medium_test\"\n",
    "filename = \"2023-10-13_14-17-42_gpt2-large_test\"\n",
    "\n",
    "with open(f'../experiment_data/4_head_attributions/{filename}.json') as f:\n",
    "    head_attributions = json.load(f)\n",
    "\n",
    "trimmed_texts_filename = head_attributions['prior_filename']\n",
    "with open(f'../experiment_data/3_trimmed_texts/{trimmed_texts_filename}.json') as f:\n",
    "    trimmed_texts = json.load(f)\n",
    "\n",
    "max_activating_filename = trimmed_texts['prior_filename']\n",
    "with open(f'../experiment_data/2_max_activating_texts/{max_activating_filename}.json') as f:\n",
    "    max_activating = json.load(f)\n",
    "\n",
    "neuron_filename = max_activating['prior_filename']\n",
    "with open(f'../experiment_data/1_next_token_neurons/{neuron_filename}.json') as f:\n",
    "    neurons_data = json.load(f)\n",
    "\n",
    "neurons = [tuple_str_to_tuple(neuron_str) for neuron_str in head_attributions['head_attributions'].keys()]\n",
    "\n",
    "neuron_to_token = {tuple_str_to_tuple(neuron_str): token_data['token'] for neuron_str, token_data in neurons_data['neurons'].items()}\n",
    "\n",
    "# Parameters\n",
    "parameters = head_attributions['parameters']\n",
    "model_name = parameters['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "\n",
    "import json\n",
    "# Load the jsonl\n",
    "with open(f'../experiment_data/5_head_explanations/2024-02-15_01-59-23_pythia-1.4b_train_results.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [json.loads(line) for line in lines]\n",
    "\n",
    "x = lines[0]\n",
    "# print(x[0]['messages'])\n",
    "exp_prompt_to_exp = {x[0]['messages'][0]['content']: x[1]['choices'][0]['message']['content'] for x in lines}\n",
    "\n",
    "with open('../experiment_data/5_head_explanations/2024-02-15_01-59-23_pythia-1.4b_train_prompts_dict.json') as f:\n",
    "    nh_to_exp_prompt = json.load(f)\n",
    "\n",
    "nh_to_exp_prompt = {tuple_str_to_tuple(k): v for k, v in nh_to_exp_prompt.items()}\n",
    "\n",
    "nh_to_exp = {nh: exp_prompt_to_exp[exp_prompt] for nh, exp_prompt in nh_to_exp_prompt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../experiment_data/text_list_dict_test.pkl', 'rb') as f:\n",
    "    dataset_text_dict = pickle.load(f)\n",
    "\n",
    "dataset_text_list = [x['text'] for x in dataset_text_dict]\n",
    "dataset = dataset_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_to_prompts = {tuple_str_to_tuple(neuron): \n",
    "                     list(head_attribution.keys()) \n",
    "                     for neuron, head_attribution in head_attributions['head_attributions'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_prompts_dict = generate_classify_prompt_dict(\n",
    "    nh_to_exp = nh_to_exp,\n",
    "    neuron_to_prompts=neuron_to_prompts,\n",
    "    neuron_to_token=neuron_to_token,\n",
    "    max_per_nh=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13460"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_prompts = []\n",
    "for nh, exp in gpt_4_prompts_dict.items():\n",
    "    gpt_4_prompts += list(exp.keys())\n",
    "\n",
    "len(gpt_4_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2660"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_4_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "            {\"model\":\"gpt-4-1106-preview\",\n",
    "            \"messages\":[{\"role\": \"user\", \"content\": gpt_4_prompt}],\n",
    "            \"max_tokens\":1, \n",
    "        } for gpt_4_prompt in gpt_4_prompts]\n",
    "\n",
    "filepath = f\"../experiment_data/6_explanation_eval/{filename}_mid_aclcn.jsonl\"\n",
    "if os.path.isfile(filepath):\n",
    "    raise Exception(\"File already exists!\")\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    for job in jobs:\n",
    "        json_string = json.dumps(job)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'parameters': parameters,\n",
    "    'prior_filename': filename,\n",
    "    'classify_filepath': filepath,\n",
    "    'classify_prompts': {str(k):v for k,v in gpt_4_prompts_dict.items()}\n",
    "}\n",
    "\n",
    "# Save json to ../experiment_data/2_max_activating_texts\n",
    "timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(int(time.time())))\n",
    "new_filename = f\"{timestamp}_{model_name}_test_mid_aclcn.json\"\n",
    "\n",
    "with open(f'../experiment_data/6_explanation_eval/{new_filename}', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2318858\n",
      "23.18858\n"
     ]
    }
   ],
   "source": [
    "prompt_token_cost = 0.01/1000\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "# Count the number of tokens in `gpt_4_prompts`\n",
    "prompt_tokens = 0\n",
    "for gpt_4_prompt in gpt_4_prompts:\n",
    "    prompt_tokens += len(encoding.encode(gpt_4_prompt))\n",
    "\n",
    "\n",
    "\n",
    "print(prompt_tokens)\n",
    "print(prompt_tokens * prompt_token_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
