{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clementneo/projects/Neuron_groups/neuron_groups/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "from src.neuron_heads import head_attribution_over_all_data\n",
    "from src.datahandlers import ActivatingDataset\n",
    "from src.utils import tuple_str_to_tuple\n",
    "from src.neuron_explain import generate_classify_prompt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"2023-10-13_13-51-37_gpt2-small_test\"\n",
    "# filename = \"2023-10-13_14-02-06_gpt2-medium_test\"\n",
    "# filename = \"2023-10-13_14-17-42_gpt2-large_test\"\n",
    "filename = \"2023-10-14_18-35-10_gpt2-large_mid_test\"\n",
    "\n",
    "with open(f'../experiment_data/4_head_attributions/{filename}.json') as f:\n",
    "    head_attributions = json.load(f)\n",
    "\n",
    "trimmed_texts_filename = head_attributions['prior_filename']\n",
    "with open(f'../experiment_data/3_trimmed_texts/{trimmed_texts_filename}.json') as f:\n",
    "    trimmed_texts = json.load(f)\n",
    "\n",
    "max_activating_filename = trimmed_texts['prior_filename']\n",
    "with open(f'../experiment_data/2_max_activating_texts/{max_activating_filename}.json') as f:\n",
    "    max_activating = json.load(f)\n",
    "\n",
    "neuron_filename = max_activating['prior_filename']\n",
    "with open(f'../experiment_data/1_next_token_neurons/{neuron_filename}.json') as f:\n",
    "    neurons_data = json.load(f)\n",
    "\n",
    "neurons = [tuple_str_to_tuple(neuron_str) for neuron_str in head_attributions['head_attributions'].keys()]\n",
    "\n",
    "neuron_to_token = {tuple_str_to_tuple(neuron_str): token_data['token'] for neuron_str, token_data in neurons_data['neurons'].items()}\n",
    "\n",
    "# Parameters\n",
    "parameters = head_attributions['parameters']\n",
    "model_name = parameters['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "\n",
    "import json\n",
    "# Load the jsonl\n",
    "with open('../experiment_data/5_head_explanations/2023-10-14_16-00-09_gpt2-large_mid_prompts_mid_results.jsonl', 'r') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-43-12_gpt2-small_prompts_results.jsonl', 'r') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-23-51_gpt2-medium_prompts_results.jsonl', 'r') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-41-45_gpt2-large_prompts_results.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [json.loads(line) for line in lines]\n",
    "\n",
    "x = lines[0]\n",
    "# print(x[0]['messages'])\n",
    "exp_prompt_to_exp = {x[0]['messages'][0]['content']: x[1]['choices'][0]['message']['content'] for x in lines}\n",
    "\n",
    "with open('../experiment_data/5_head_explanations/2023-10-14_16-00-09_gpt2-large_mid_prompts_dict.json') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-43-12_gpt2-small_prompts_dict.json') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-23-51_gpt2-medium_prompts_dict.json') as f:\n",
    "# with open('../experiment_data/5_head_explanations/2023-10-12_14-41-45_gpt2-large_prompts_dict.json') as f:\n",
    "    nh_to_exp_prompt = json.load(f)\n",
    "\n",
    "nh_to_exp_prompt = {tuple_str_to_tuple(k): v for k, v in nh_to_exp_prompt.items()}\n",
    "\n",
    "nh_to_exp = {nh: exp_prompt_to_exp[exp_prompt] for nh, exp_prompt in nh_to_exp_prompt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../experiment_data/text_list_dict_test.pkl', 'rb') as f:\n",
    "    dataset_text_dict = pickle.load(f)\n",
    "\n",
    "dataset_text_list = [x['text'] for x in dataset_text_dict]\n",
    "dataset = dataset_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_to_prompts = {tuple_str_to_tuple(neuron): \n",
    "                     list(head_attribution.keys()) \n",
    "                     for neuron, head_attribution in head_attributions['head_attributions'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_prompts_dict = generate_classify_prompt_dict(\n",
    "    nh_to_exp = nh_to_exp,\n",
    "    neuron_to_prompts=neuron_to_prompts,\n",
    "    neuron_to_token=neuron_to_token,\n",
    "    max_per_nh=20\n",
    ")\n",
    "\n",
    "# gpt_4_prompts_dict_10 = generate_classify_prompt_dict(\n",
    "#     nh_to_exp = nh_to_exp,\n",
    "#     neuron_to_prompts=neuron_to_prompts,\n",
    "#     neuron_to_token=neuron_to_token,\n",
    "#     max_per_nh=10\n",
    "# )\n",
    "\n",
    "# gpt_4_prompts_dict_20 = generate_classify_prompt_dict(\n",
    "#     nh_to_exp = nh_to_exp,\n",
    "#     neuron_to_prompts=neuron_to_prompts,\n",
    "#     neuron_to_token=neuron_to_token,\n",
    "#     max_per_nh=20\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_prompts = []\n",
    "for nh, exp in gpt_4_prompts_dict.items():\n",
    "    gpt_4_prompts += list(exp.keys())\n",
    "\n",
    "len(gpt_4_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "            {\"model\":\"gpt-4\",\n",
    "            \"messages\":[{\"role\": \"user\", \"content\": gpt_4_prompt}],\n",
    "            \"max_tokens\":1, \n",
    "        } for gpt_4_prompt in gpt_4_prompts]\n",
    "\n",
    "filepath = f\"../experiment_data/6_explanation_eval/{filename}_prompts_20.jsonl\"\n",
    "if os.path.isfile(filepath):\n",
    "    raise Exception(\"File already exists!\")\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    for job in jobs:\n",
    "        json_string = json.dumps(job)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'parameters': parameters,\n",
    "    'prior_filename': filename,\n",
    "    'classify_filepath': filepath,\n",
    "    'classify_prompts': {str(k):v for k,v in gpt_4_prompts_dict.items()}\n",
    "}\n",
    "\n",
    "# Save json to ../experiment_data/2_max_activating_texts\n",
    "timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(int(time.time())))\n",
    "new_filename = f\"{timestamp}_{model_name}_mid_test_20.json\"\n",
    "\n",
    "with open(f'../experiment_data/6_explanation_eval/{new_filename}', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.6\n",
      "63.86\n",
      "Total cost: 7.513859999999999\n"
     ]
    }
   ],
   "source": [
    "# Open jsonl\n",
    "# filepath = f\"../experiment_data/6_explanation_eval/2023-10-13_13-51-37_gpt2-small_test_prompts_results.jsonl\"\n",
    "# filepath = f\"../experiment_data/6_explanation_eval/2023-10-13_14-02-06_gpt2-medium_test_prompts_results.jsonl\"\n",
    "# filepath = f\"../experiment_data/6_explanation_eval/2023-10-13_14-17-42_gpt2-large_test_prompts_results.jsonl\"\n",
    "#small 11.6, med 15.3,  large 36.96, \n",
    "\n",
    "# Explanations\n",
    "# filepath = f\"../experiment_data/5_head_explanations/2023-10-12_14-43-12_gpt2-small_prompts_results.jsonl\"\n",
    "filepath = \"../experiment_data/5_head_explanations/2023-10-12_14-23-51_gpt2-medium_prompts_results.jsonl\"\n",
    "# filepath = \"../experiment_data/5_head_explanations/2023-10-12_14-41-45_gpt2-large_prompts_results.jsonl\"\n",
    "# small 5.3, med 7.5,  large 18\n",
    "\n",
    "print(5.3+7.5+12.8)\n",
    "print(11.6+15.3+36.96)\n",
    "\n",
    "with open(filepath, \"r\") as f:\n",
    "    results = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "usages = [results[n][1]['usage'] for n in range(len(results))]\n",
    "prompt_token_cost = 0.03/1000\n",
    "completion_token_cost = 0.06/1000\n",
    "prompt_cost = sum([x['prompt_tokens'] for x in usages]) * prompt_token_cost\n",
    "completion_cost = sum([x['completion_tokens'] for x in usages]) * completion_token_cost\n",
    "total_cost = prompt_cost + completion_cost\n",
    "\n",
    "print(f\"Total cost: {total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_4_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183566\n",
      "35.50698\n"
     ]
    }
   ],
   "source": [
    "prompt_token_cost = 0.03/1000\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "# Count the number of tokens in `gpt_4_prompts`\n",
    "prompt_tokens = 0\n",
    "for gpt_4_prompt in gpt_4_prompts:\n",
    "    prompt_tokens += len(encoding.encode(gpt_4_prompt))\n",
    "\n",
    "\n",
    "\n",
    "print(prompt_tokens)\n",
    "print(prompt_tokens * prompt_token_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_attribution_dict = head_attributions['head_attributions']\n",
    "# nh_to_pos_examples = {}\n",
    "\n",
    "# NUM_TEST_EXAMPLES = 10\n",
    "# for nh, data in gpt_4_prompts_dict_10.items():\n",
    "#     neuron_str, head = str((nh[0], nh[1])), nh[2]\n",
    "#     num_pos_examples = 0\n",
    "#     for i, trunc_prompt_with_token in enumerate(data.values()):\n",
    "#         trunc_prompt = trunc_prompt_with_token[:-len(neuron_to_token[(nh[0], nh[1])])]\n",
    "#         if head in head_attribution_dict[neuron_str][trunc_prompt]:\n",
    "#             num_pos_examples += 1\n",
    "#     nh_to_pos_examples[nh] = num_pos_examples/NUM_TEST_EXAMPLES\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.hist(nh_to_pos_examples.values(), bins=8)\n",
    "# # plt.show()\n",
    "\n",
    "# head_attribution_dict = head_attributions['head_attributions']\n",
    "# nh_to_pos_examples = {}\n",
    "# NUM_TEST_EXAMPLES = 20\n",
    "\n",
    "# for nh, data in gpt_4_prompts_dict_20.items():\n",
    "#     neuron_str, head = str((nh[0], nh[1])), nh[2]\n",
    "#     num_pos_examples = 0\n",
    "#     for i, trunc_prompt_with_token in enumerate(data.values()):\n",
    "#         if i >= NUM_TEST_EXAMPLES: break\n",
    "#         trunc_prompt = trunc_prompt_with_token[:-len(neuron_to_token[(nh[0], nh[1])])]\n",
    "#         if head in head_attribution_dict[neuron_str][trunc_prompt]:\n",
    "#             num_pos_examples += 1\n",
    "#     nh_to_pos_examples[nh] = num_pos_examples/NUM_TEST_EXAMPLES\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.hist(nh_to_pos_examples.values(), alpha=0.5, bins=8)\n",
    "# # Put this to 50% transparency\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test_prompts and _test_prompts_20\n",
    "# with open(\"../experiment_data/6_explanation_eval/2023-10-13_14-17-42_gpt2-large_test_prompts.jsonl\", 'rb') as f:\n",
    "# with open(\"../experiment_data/6_explanation_eval/2023-10-13_14-02-06_gpt2-medium_test_prompts.jsonl\", 'rb') as f:\n",
    "with open(\"../experiment_data/6_explanation_eval/2023-10-13_13-51-37_gpt2-small_test_prompts.jsonl\", \"rb\") as f:\n",
    "    test_prompts = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "# with open(\"../experiment_data/6_explanation_eval/2023-10-13_14-17-42_gpt2-large_test_prompts_20.jsonl\", 'rb') as f:\n",
    "# with open(\"../experiment_data/6_explanation_eval/2023-10-13_14-02-06_gpt2-medium_test_prompts_20.jsonl\", 'rb') as f:\n",
    "with open(\"../experiment_data/6_explanation_eval/2023-10-13_13-51-37_gpt2-small_test_prompts_20.jsonl\", \"rb\") as f:\n",
    "    test_prompts_20 = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070\n",
      "4096\n",
      "2026\n"
     ]
    }
   ],
   "source": [
    "print(len(test_prompts))\n",
    "print(len(test_prompts_20))\n",
    "\n",
    "# Check how many elements in test_prompts_20 that are not in test_prompts\n",
    "\n",
    "test_prompts_20_prompts = [x['messages'][0]['content'] for x in test_prompts_20]\n",
    "test_prompts_prompts = [x['messages'][0]['content'] for x in test_prompts]\n",
    "\n",
    "new_gpt_4_prompts = [x for x in test_prompts_20_prompts if x not in test_prompts_prompts]\n",
    "\n",
    "print(len(new_gpt_4_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "            {\"model\":\"gpt-4\",\n",
    "            \"messages\":[{\"role\": \"user\", \"content\": gpt_4_prompt}],\n",
    "            \"max_tokens\":1, \n",
    "        } for gpt_4_prompt in new_gpt_4_prompts]\n",
    "\n",
    "# filename = \"2023-10-13_14-17-42_gpt2-large_test\"\n",
    "# filename = \"2023-10-13_14-02-06_gpt2-medium_test\"\n",
    "filename = \"2023-10-13_13-51-37_gpt2-small_test\"\n",
    "\n",
    "filepath = f\"../experiment_data/6_explanation_eval/{filename}_prompts_10.jsonl\"\n",
    "# if os.path.isfile(filepath):\n",
    "#     raise Exception(\"File already exists!\")\n",
    "\n",
    "# with open(filepath, \"w\") as f:\n",
    "#     for job in jobs:\n",
    "#         json_string = json.dumps(job)\n",
    "#         f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'parameters': parameters,\n",
    "    'prior_filename': filename,\n",
    "    'classify_filepath': filepath,\n",
    "    'classify_prompts': {str(k):v for k,v in gpt_4_prompts_dict.items()}\n",
    "}\n",
    "\n",
    "# Save json to ../experiment_data/2_max_activating_texts\n",
    "timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(int(time.time())))\n",
    "new_filename = f\"{filename}_10.json\"\n",
    "\n",
    "with open(f'../experiment_data/6_explanation_eval/{new_filename}', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
