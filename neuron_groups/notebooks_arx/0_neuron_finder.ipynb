{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook\n"
     ]
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    pio.renderers.default = \"colab\"\n",
    "    %pip install transformer-lens fancy-einsum\n",
    "    %pip install -U kaleido # kaleido only works if you restart the runtime. Required to write figures to disk (final cell)\n",
    "except:\n",
    "    print(\"Running as a Jupyter notebook\")\n",
    "    pio.renderers.default = \"vscode\"\n",
    "    from IPython import get_ipython\n",
    "    ipython = get_ipython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from fancy_einsum import einsum\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, utils, ActivationCache\n",
    "from torchtyping import TensorType as TT\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import einops\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # https://stackoverflow.com/q/62691279\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: circuitsvis in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (1.39.1)\n",
      "Requirement already satisfied: torch<2.0,>=1.10 in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (from circuitsvis) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (from circuitsvis) (5.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.23 in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (from circuitsvis) (1.24.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/clementneo/projects/aan/aan/lib/python3.10/site-packages (from torch<2.0,>=1.10->circuitsvis) (4.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install circuitsvis\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default='vscode'\n",
    "\n",
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-large into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-large\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding top token-aligned neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L31N3621:  only (5.47)\n",
      "L31N364:  number (5.32)\n",
      "L31N2918:  go (5.09)\n",
      "L31N4378:  together (5.04)\n",
      "L31N988:  called (5.02)\n",
      "L31N2658:  first (4.90)\n",
      "L31N2692:  used (4.67)\n",
      "L31N4941:  within (4.50)\n",
      "L31N2415:  way (4.37)\n",
      "L31N1407:  out (4.27)\n",
      "L32N4964:  too (5.54)\n",
      "L32N2412:  will (5.11)\n",
      "L32N4282:  right (4.93)\n",
      "L32N3151:  over (4.80)\n",
      "L32N1155:  out (4.68)\n",
      "L32N1386:  once (4.45)\n",
      "L32N3582:  her (4.26)\n",
      "L32N4882:  class (4.21)\n",
      "L32N3477:  use (4.20)\n",
      "L32N406:  much (4.20)\n",
      "L33N1202:  so (6.02)\n",
      "L33N524:  state (5.66)\n",
      "L33N1582:  RandomRedditor (5.30)\n",
      "L33N4446:  about (4.55)\n",
      "L33N204:  following (4.46)\n",
      "L33N4900:  of (4.32)\n",
      "L33N2322:  after (4.12)\n",
      "L33N3278:  around (4.12)\n",
      "L33N1299:  last (4.08)\n",
      "L33N52:  by (3.96)\n",
      "L34N4012:  off (6.54)\n",
      "L34N4262:  down (5.78)\n",
      "L34N320:  back (5.68)\n",
      "L34N5095:  well (5.32)\n",
      "L34N2599:  there (4.88)\n",
      "L34N2442:  up (4.46)\n",
      "L34N4494:  no (4.45)\n",
      "L34N4199:  after (4.34)\n",
      "L34N727:  under (4.14)\n",
      "L34N4410:  as (3.21)\n",
      "L35N4518:  issue (3.79)\n",
      "L35N48:  close (3.53)\n",
      "L35N5014:  won (3.10)\n",
      "L35N3724:  high (3.05)\n",
      "L35N3360:  very (3.00)\n",
      "L35N885:  His (2.84)\n",
      "L35N4924:  of (2.82)\n",
      "L35N274:  サーティ (2.61)\n",
      "L35N2369:  The (2.60)\n",
      "L35N4638:  power (2.41)\n"
     ]
    }
   ],
   "source": [
    "results = {key: {} for key in [31, 32, 33, 34, 35]}\n",
    "\n",
    "\n",
    "for n in results.keys():\n",
    "    n_layer_neurons = model.W_out[n, :, :]\n",
    "    unembedding = model.W_U\n",
    "    dot_product = einsum(\"neuron embed, embed token -> neuron token\", n_layer_neurons, unembedding)\n",
    "    values, indices = torch.max(dot_product, dim=-1)\n",
    "\n",
    "    num = 5000\n",
    "    top_values, top_indices = torch.topk(values, k=num)\n",
    "    neurons_to_find = 10\n",
    "    neurons_found = 0\n",
    "    for i in range(num):\n",
    "\n",
    "        str_token = model.to_string(indices[top_indices[i]])\n",
    "        if len(str_token) <= 2 or str_token[0] != \" \":\n",
    "            continue\n",
    "        print(f\"L{n}N{top_indices[i]}: {str_token} ({top_values[i]:.2f})\")\n",
    "        results[n][top_indices[i].item()] = [str_token, top_values[i].item()]\n",
    "\n",
    "        neurons_found += 1\n",
    "        if neurons_found >= neurons_to_find:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neuron_finder_results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
